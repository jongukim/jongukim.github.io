<!doctype html>
<html lang="en">
<head>
<title>NVIDIA Apex</title>
<!-- 2019-06-17 월 15:46 -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="generator" content="Org-mode">

<link  href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.5/css/bootstrap.min.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.5/js/bootstrap.min.js"></script>
<style type="text/css">
/* org mode styles on top of twbs */

html {
    position: relative;
    min-height: 100%;
}

body {
    font-size: 18px;
    margin-bottom: 105px;
}

footer {
    position: absolute;
    bottom: 0;
    width: 100%;
    height: 101px;
    background-color: #f5f5f5;
}

footer > div {
    padding: 10px;
}

footer p {
    margin: 0 0 5px;
    text-align: center;
    font-size: 16px;
}

#table-of-contents {
    margin-top: 20px;
    margin-bottom: 20px;
}

blockquote p {
    font-size: 18px;
}

pre {
    font-size: 16px;
}

.footpara {
    display: inline-block;
}

figcaption {
  font-size: 16px;
  color: #666;
  font-style: italic;
  padding-bottom: 15px;
}

/* from twbs docs */

.bs-docs-sidebar.affix {
    position: static;
}
@media (min-width: 768px) {
    .bs-docs-sidebar {
        padding-left: 20px;
    }
}

/* All levels of nav */
.bs-docs-sidebar .nav > li > a {
    display: block;
    padding: 4px 20px;
    font-size: 14px;
    font-weight: 500;
    color: #999;
}
.bs-docs-sidebar .nav > li > a:hover,
.bs-docs-sidebar .nav > li > a:focus {
    padding-left: 19px;
    color: #A1283B;
    text-decoration: none;
    background-color: transparent;
    border-left: 1px solid #A1283B;
}
.bs-docs-sidebar .nav > .active > a,
.bs-docs-sidebar .nav > .active:hover > a,
.bs-docs-sidebar .nav > .active:focus > a {
    padding-left: 18px;
    font-weight: bold;
    color: #A1283B;
    background-color: transparent;
    border-left: 2px solid #A1283B;
}

/* Nav: second level (shown on .active) */
.bs-docs-sidebar .nav .nav {
    display: none; /* Hide by default, but at >768px, show it */
    padding-bottom: 10px;
}
.bs-docs-sidebar .nav .nav > li > a {
    padding-top: 1px;
    padding-bottom: 1px;
    padding-left: 30px;
    font-size: 12px;
    font-weight: normal;
}
.bs-docs-sidebar .nav .nav > li > a:hover,
.bs-docs-sidebar .nav .nav > li > a:focus {
    padding-left: 29px;
}
.bs-docs-sidebar .nav .nav > .active > a,
.bs-docs-sidebar .nav .nav > .active:hover > a,
.bs-docs-sidebar .nav .nav > .active:focus > a {
    padding-left: 28px;
    font-weight: 500;
}

/* Nav: third level (shown on .active) */
.bs-docs-sidebar .nav .nav .nav {
    padding-bottom: 10px;
}
.bs-docs-sidebar .nav .nav .nav > li > a {
    padding-top: 1px;
    padding-bottom: 1px;
    padding-left: 40px;
    font-size: 12px;
    font-weight: normal;
}
.bs-docs-sidebar .nav .nav .nav > li > a:hover,
.bs-docs-sidebar .nav .nav .nav > li > a:focus {
    padding-left: 39px;
}
.bs-docs-sidebar .nav .nav .nav > .active > a,
.bs-docs-sidebar .nav .nav .nav > .active:hover > a,
.bs-docs-sidebar .nav .nav .nav > .active:focus > a {
    padding-left: 38px;
    font-weight: 500;
}

/* Show and affix the side nav when space allows it */
@media (min-width: 992px) {
    .bs-docs-sidebar .nav > .active > ul {
        display: block;
    }
    /* Widen the fixed sidebar */
    .bs-docs-sidebar.affix,
    .bs-docs-sidebar.affix-bottom {
        width: 213px;
    }
    .bs-docs-sidebar.affix {
        position: fixed; /* Undo the static from mobile first approach */
        top: 20px;
    }
    .bs-docs-sidebar.affix-bottom {
        position: absolute; /* Undo the static from mobile first approach */
    }
    .bs-docs-sidebar.affix .bs-docs-sidenav,.bs-docs-sidebar.affix-bottom .bs-docs-sidenav {
        margin-top: 0;
        margin-bottom: 0
    }
}
@media (min-width: 1200px) {
    /* Widen the fixed sidebar again */
    .bs-docs-sidebar.affix-bottom,
    .bs-docs-sidebar.affix {
        width: 263px;
    }
}
</style>
<script type="text/javascript">
$(function() {
    'use strict';

    $('.bs-docs-sidebar li').first().addClass('active');

    $(document.body).scrollspy({target: '.bs-docs-sidebar'});

    $('.bs-docs-sidebar').affix();
});
</script>
</head>
<body>
<div id="content" class="container">
<div class="row"><div class="col-md-9"><h1 class="title">NVIDIA Apex</h1>
<p>
Mixed precision을 편리하게 사용할 수 있는 apex.amp와 병렬처리를 편하게 할 수 있는 apex.parallel로 구성.
현재 버전은 0.1이며, <a href="https://nvidia.github.io/apex/amp.html">문서</a>도 제공 중.
</p>

<div id="outline-container-sec-1" class="outline-2">
<h2 id="sec-1"><span class="section-number-2">1</span> apex.amp</h2>
<div class="outline-text-2" id="text-1">
<p>
몇 줄만 추가하면 FP16을 쉽게 활용할수 있다.
</p>
</div>

<div id="outline-container-sec-1-1" class="outline-3">
<h3 id="sec-1-1"><span class="section-number-3">1.1</span> model과 optimizer</h3>
<div class="outline-text-3" id="text-1-1">
<div class="org-src-container">

<pre class="src src-python"><span style="color: #51afef;">from</span> apex <span style="color: #51afef;">import</span> amp

<span style="color: #dcaeea;">model</span> = ...
<span style="color: #dcaeea;">optimizer</span> = ...
<span style="color: #dcaeea;">model</span>, <span style="color: #dcaeea;">optimizer</span> = amp.initialize<span style="color: #51afef;">(</span>model, optimizer, opt_level=<span style="color: #98be65;">"O2"</span><span style="color: #51afef;">)</span>
</pre>
</div>

<p>
위와 같이 모델과 optimizer를 선언한 후 amp.initialize로 한 번 감싸주면 끝.
optlevel은 O0 ~ O3가 있다.
</p>

<ul class="org-ul">
<li>O0: FP32
</li>
<li>O1: Mixed precision
</li>
<li>O2: Almost FP16
</li>
<li>O3: FP16
</li>
</ul>
</div>
</div>

<div id="outline-container-sec-1-2" class="outline-3">
<h3 id="sec-1-2"><span class="section-number-3">1.2</span> loss.backward()</h3>
<div class="outline-text-3" id="text-1-2">
<p>
변경할 것이 하나 더 있다.
loss.backward() 코드를 다음과 같이 바꿔주면 된다.
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #51afef;">with</span> amp.scale_loss<span style="color: #51afef;">(</span>loss, optimizer<span style="color: #51afef;">)</span> <span style="color: #51afef;">as</span> scaled_loss:
  scaled_loss.backward<span style="color: #51afef;">()</span>
</pre>
</div>
</div>
</div>
</div>

<div id="outline-container-sec-2" class="outline-2">
<h2 id="sec-2"><span class="section-number-2">2</span> apex.parallel</h2>
<div class="outline-text-2" id="text-2">
<p>
현재 내 환경은 싱글 노드 multi-GPU다.
싱글 노드에서도 DataParallel보다 DistributedDataParallel(DDP)을 사용하는 것이 multi-GPU를 효율적으로 사용할 수 있다고 문서에 기술되어 있다.
DDP를 사용하려면 코드를 제법 고쳐야 하는데, apex는 조금 더 wrapping된 DPP를 제공한다.
</p>
</div>

<div id="outline-container-sec-2-1" class="outline-3">
<h3 id="sec-2-1"><span class="section-number-3">2.1</span> 모델 부분</h3>
<div class="outline-text-3" id="text-2-1">
<p>
DataParallel을 사용할 때와 마찬가지로 다음과 같이 모델을 감싸주면 모델에 대한 병렬처리가 가능하도록 해준다.
</p>
<div class="org-src-container">

<pre class="src src-python"><span style="color: #51afef;">from</span> apex.parallel <span style="color: #51afef;">import</span> DistributedDataParallel <span style="color: #51afef;">as</span> DDP

<span style="color: #dcaeea;">model</span> = DDP<span style="color: #51afef;">(</span>model, delay_allreduce=<span style="color: #a9a1e1;">True</span><span style="color: #51afef;">)</span>
</pre>
</div>

<p>
delay_allreduce는 기본적으로 False인데, 많은 예제에서 True로 설정하고 있어서 그냥 따라했다.
</p>

<p>
학습을 실행하는 파이썬 스크립트에는 변경이 조금 필요하다.
DDP는 torch.distributed.launch 모듈을 통해 multi-process로 실행한다.
실행 명렁어는 다음과 같은 형태이다.
</p>
</div>
</div>

<div id="outline-container-sec-2-2" class="outline-3">
<h3 id="sec-2-2"><span class="section-number-3">2.2</span> 실행 스크립트</h3>
<div class="outline-text-3" id="text-2-2">
<div class="org-src-container">

<pre class="src src-shell">python3 -m torch.distributed.launch --nproc_per_node=6 train.py ...
</pre>
</div>

<p>
&#x2013;nproc_per_node는 로컬 머신에 있는 GPU 개수를 전달하면 된다.
나는 6개의 V100 GPU를 가지고 있다.
</p>

<p>
위와 같이 명령어를 실행하면 자동으로 여러 개의 train.py 프로세스가 생생되는데 &#x2013;local_rank라는 인자를 자동으로 붙여서 실행하게 된다.
따라서 train.py 스크립트는 다음과 같이 &#x2013;local_rank 인자를 받아야 한다.
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #51afef;">import</span> argparse

<span style="color: #dcaeea;">parser</span> = argparse.ArgumentParser<span style="color: #51afef;">(</span>description=<span style="color: #98be65;">"training script"</span><span style="color: #51afef;">)</span>
parser.add_argument<span style="color: #51afef;">(</span><span style="color: #98be65;">"--local_rank"</span>, <span style="color: #c678dd;">type</span>=<span style="color: #c678dd;">int</span>, default=0<span style="color: #51afef;">)</span>
...
<span style="color: #dcaeea;">args</span> = parser.parse_args<span style="color: #51afef;">()</span>
<span style="color: #dcaeea;">rank</span> = args.local_rank
</pre>
</div>

<p>
그리고 각 스크립트가 넘겨받은 인자에 따라 GPU를 사용하도록 아래와 같이 설정한다.
</p>
<div class="org-src-container">

<pre class="src src-python">torch.cuda.set_device<span style="color: #51afef;">(</span>rank<span style="color: #51afef;">)</span>
</pre>
</div>

<p>
GPU간 통신은 NCCL을 사용하도록 한다.
</p>
<div class="org-src-container">

<pre class="src src-python"><span style="color: #51afef;">import</span> torch.distributed <span style="color: #51afef;">as</span> dist

dist.init_process_group<span style="color: #51afef;">(</span>backend=<span style="color: #98be65;">"nccl"</span><span style="color: #51afef;">)</span>
</pre>
</div>
</div>
</div>

<div id="outline-container-sec-2-3" class="outline-3">
<h3 id="sec-2-3"><span class="section-number-3">2.3</span> DataLoader와 DistributedSampler</h3>
<div class="outline-text-3" id="text-2-3">
<p>
또 하나 변경해주어야 하는 것은 DataLoader 부분이다.
분산 스크립트가 데이터를 나누어 로드할 수 있도록 Sampler로 감싸준다.
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #51afef;">from</span> torch.utils.data <span style="color: #51afef;">import</span> DataLoader
<span style="color: #51afef;">from</span> torch.utils.data.distributed <span style="color: #51afef;">import</span> DistributedSampler

<span style="color: #dcaeea;">dataset</span> = ...
<span style="color: #dcaeea;">samper</span> = DistributedSampler<span style="color: #51afef;">(</span>dataset<span style="color: #51afef;">)</span>
<span style="color: #dcaeea;">data_loader</span> = DataLoader<span style="color: #51afef;">(</span>dataset, sampler=sampler, ...<span style="color: #51afef;">)</span>
</pre>
</div>

<p>
dataset은 본래 CPU 학습이나 단일 GPU 사용 시와 마찬가지로  torch.utils.data.Dataset을 상속 받은 인스턴스를 사용하면 된다.
DataLoader에는 num_workers를 지정해주는 것도 속도 개선이 도움이 되었다.
</p>
</div>
</div>

<div id="outline-container-sec-2-4" class="outline-3">
<h3 id="sec-2-4"><span class="section-number-3">2.4</span> Logging</h3>
<div class="outline-text-3" id="text-2-4">
<p>
여러 스크립트가 실행되기 때문에 로그 출력 코드를 그대로 사용하면 출력이 중복된다.
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #51afef;">if</span> rank == 0:
  logger.info<span style="color: #51afef;">(</span>...<span style="color: #51afef;">)</span>
</pre>
</div>

<p>
위와 같은 형태로 rank가 0일 때만 출력하면 된다.
</p>
</div>
</div>

<div id="outline-container-sec-2-5" class="outline-3">
<h3 id="sec-2-5"><span class="section-number-3">2.5</span> Model saving/loading</h3>
<div class="outline-text-3" id="text-2-5">
<p>
마찬가지로 모델 저장도 rank가 0일 때만 처리하면 된다.
그리고 현재 모델이 DDP로 한 번 감싸져 있으므로 만약 multi-GPU가 아닌 다른 환경에서 weights를 로드하고 싶다면,
</p>

<div class="org-src-container">

<pre class="src src-python">torch.save<span style="color: #51afef;">(</span><span style="color: #c678dd;">{</span><span style="color: #98be65;">"model"</span>: model.state_dict<span style="color: #98be65;">()</span>,
            <span style="color: #98be65;">"params"</span>: model.module.state_dict<span style="color: #98be65;">()</span>,
            <span style="color: #98be65;">"optim"</span>: optimizer.state_dict<span style="color: #98be65;">()</span><span style="color: #c678dd;">}</span><span style="color: #51afef;">)</span>
</pre>
</div>

<p>
와 같이 저장해서 model과 optim은 학습을 이어갈 때나 multi-GPU 환경에서 inference할 때 사용하고, CPU나 단일 GPU 환경에서 사용할 때는 params를 로드하여 사용하면 된다.
</p>
</div>
</div>
</div>
</div><div class="col-md-3"><nav id="table-of-contents">
<div id="text-table-of-contents" class="bs-docs-sidebar">
<ul class="nav">
<li><a href="#sec-1">1. apex.amp</a>
<ul class="nav">
<li><a href="#sec-1-1">1.1. model과 optimizer</a></li>
<li><a href="#sec-1-2">1.2. loss.backward()</a></li>
</ul>
</li>
<li><a href="#sec-2">2. apex.parallel</a>
<ul class="nav">
<li><a href="#sec-2-1">2.1. 모델 부분</a></li>
<li><a href="#sec-2-2">2.2. 실행 스크립트</a></li>
<li><a href="#sec-2-3">2.3. DataLoader와 DistributedSampler</a></li>
<li><a href="#sec-2-4">2.4. Logging</a></li>
<li><a href="#sec-2-5">2.5. Model saving/loading</a></li>
</ul>
</li>
</ul>
</div>
</nav>
</div></div></div>
<footer id="postamble" class="">
<div><p class="date">Created: 2019-06-17 월 15:46</p>
<p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 26.2 (<a href="http://orgmode.org">Org-mode</a> 9.1.9)</p>
</div>
</footer>
</body>
</html>
